---
title: "chapter-2-notes"
output: 
  html_document: 
    keep_md: yes
---

# Highlights

> Bayesian analysis provides a general way to discover relevant information and process it logically. Just don't think that it is the only way.

> In order to make good inference about what actually happened, it helps to consider everything that could have happened.

> ... if there are important differences between the model and reality, then there is no logical gaurantee of large world performance. ... even if the two worlds did match, any particular sample of data could still be misleading...keep in mind two principles: (1) A model's certainty is no gaurantee that the model is a good one, (2) it is important to supervise and critique your model's work.

> It is important to check the model's inferences in light of aspects of the data it doe not know about. Such checks are an inherently creative interprise, left to the analyst and the scientific community. Golems are very bad at it.

> ... The likelihood maps each conjecture - such as a proportion of water on the globe - onto the relative number of ways the data could occur, given that possibility...the likelihood needs to tell you the probability of any possible observation, for any psosible state of the (small) world, such as a proportion of water on a globe...Just keep in mind that the job of the likelihood is to tell us the realtive number of ways to see the data, given [values for parameters].

> Data are measured and known; parameters are unknown and must be estimated from data.

> ... none of this should be understood to mean that any statistical analysis is not inherently subjective, because of course it is - lots of little subjective decisions are involved in all parts of science. It's just that priors and Bayesian data analysis are nomore inherently subjective than are likelihoods and the repeat sampling assumptions required for significance testing.

In the summary:

> ...a Bayesian model is a composite of a likelihood, a choice of parameters, and a prior. The likelihood provides the plausibility of an observation (data), given a fixed value for the parameters. The prior provides the plausibility of each possible value of the parameters, before accounting for the data.

# Grid approximation

```{r}
# define grid

p_grid <- seq(from = 0, 
              to = 1, 
              length.out = 20)

p_grid
# define prior

prior <- rep(1,20)

prior
# compute likelihood at each value in the grid

likelihood <- dbinom(6, 
                     size = 9, 
                     prob = p_grid)

likelihood
# compute product of likeligood and prior
unstd_posterior <- likelihood * prior

unstd_posterior
# standarfize posterior, so it sums to 1
posterior <- unstd_posterior / sum(unstd_posterior)

posterior
```

Now we plot it using base

```{r}

plot(p_grid,
     posterior,
     type = "b",
     xlab = "probability of water",
     ylab = "posterior_probability")
mtext("20 points")

```

Now let's wrap that in a function

```{r}

grid_approx_binom_water <- function(n_grids){
  
p_grid <- seq(from = 0, 
              to = 1, 
              length.out = n_grids)

p_grid
# define prior

prior <- rep(1,n_grids)

prior
# compute likelihood at each value in the grid

likelihood <- dbinom(6, 
                     size = 9, 
                     prob = p_grid)

likelihood
# compute product of likeligood and prior
unstd_posterior <- likelihood * prior

unstd_posterior
# standarfize posterior, so it sums to 1
posterior <- unstd_posterior / sum(unstd_posterior)

data.frame(posterior = posterior,
           p_grid = p_grid)
}

plot_grid_approx <- function(posterior_samples,
                             p_grid){
plot(x = p_grid,
     y = posterior_samples,
     type = "b",
     xlab = "probability of water",
     ylab = "posterior_probability")
mtext("20 points")
}

library(tidyverse)

  
plot_posterior <- function(data){
  ggplot(data,
         aes_string(x = "p_grid",
                    y = "posterior")) + 
  geom_point() + 
  geom_line()
}

grid_approx_binom_water(20) %>% plot_posterior()

grid_approx_binom_water(5) %>% plot_posterior()
  
grid_approx_binom_water(4) %>% plot_posterior()
  

```

Now, to replicate the different priors in Figure 2.5, try these lines of code - one at a time - for the prior grid:

```{r}


grid_approx_binom_water <- function(n_grids,
                                    p_grid = seq(from = 0, 
                                                 to = 1, 
                                                 length.out = n_grids),
                                    prior = rep(1,n_grids)){
  
# p_grid <- seq(from = 0, to = 1, length.out = n_grids)
# define prior

# prior <- rep(1,n_grids)

# compute likelihood at each value in the grid

likelihood <- dbinom(6, 
                     size = 9, 
                     prob = p_grid)

# compute product of likeligood and prior
unstd_posterior <- likelihood * prior

# standarfize posterior, so it sums to 1
posterior <- unstd_posterior / sum(unstd_posterior)

data.frame(posterior = posterior,
           p_grid = p_grid)
}

grid_approx_binom_water(n_grids = 20)

grid_approx_binom_water(n_grids = 20,
                        prior = ifelse(p_grid < 0.5, 0, 1)) %>%
  plot_posterior()

grid_approx_binom_water(n_grids = 20,
                        prior = exp(-5 * abs(p_grid-0.5))) %>%
  plot_posterior()

```

# Quadratic approximation

```{r}
# install.packages("rethinking")
library(rethinking)

globe_qa <- rethinking::map(
  alist(w ~ dbinom(9, p),
        p ~ dunif(0,1)),
  data = list(w = 6)
)

rethinking::precis(globe_qa)
```

